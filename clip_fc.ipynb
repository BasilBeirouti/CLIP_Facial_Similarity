{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10667d9-12dd-474f-a3a7-00f061cdbc35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install ftfy regex tqdm\n",
    "# !pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82a1ef1-b983-4e4a-93fb-1bf835dc125e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Preprocess and Encode Images\n",
    "def compute_clip_features(dataset, clip_model, preprocess, device):\n",
    "    clip_features = []\n",
    "    for image_pair in dataset:\n",
    "        image1, image2 = image_pair[0], image_pair[1]\n",
    "\n",
    "        # Preprocess images\n",
    "        image1 = Image.fromarray(image1.astype('uint8'), 'RGB')\n",
    "        image2 = Image.fromarray(image2.astype('uint8'), 'RGB')\n",
    "        preprocessed_image1 = preprocess(image1).unsqueeze(0).to(device)\n",
    "        preprocessed_image2 = preprocess(image2).unsqueeze(0).to(device)\n",
    "\n",
    "        # Encode images\n",
    "        with torch.no_grad():\n",
    "            features1 = clip_model.encode_image(preprocessed_image1)\n",
    "            features2 = clip_model.encode_image(preprocessed_image2)\n",
    "\n",
    "        # Flatten and concatenate features for each image pair\n",
    "        features1 = features1.view(-1)\n",
    "        features2 = features2.view(-1)\n",
    "        concatenated_features = torch.cat((features1, features2))\n",
    "\n",
    "        clip_features.append(concatenated_features.cpu())\n",
    "\n",
    "    return clip_features\n",
    "\n",
    "\n",
    "class LFWDatasetFeatures(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return features, label\n",
    "\n",
    "class CustomClassifierConcat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomClassifierConcat, self).__init__()\n",
    "\n",
    "        # Assuming each CLIP feature vector is of size 512, concatenated size is 1024\n",
    "        self.fc1 = nn.Linear(1024, 2048)  # Input size for concatenated features\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.fc3 = nn.Linear(1024, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, features):\n",
    "        out = self.fc1(features)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features = features.to(device).float()  # Ensure features are float32\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.sigmoid(outputs).round()\n",
    "        correct += (preds.squeeze() == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total_samples\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device).float(), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            correct += (preds.squeeze() == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return total_loss / len(test_loader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902ab7fe-33d9-40a7-a8a5-bd1aa0fcbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_small_dataset(features, labels, subset_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Create a smaller subset of the dataset for quick prototyping.\n",
    "    :param features: The original features.\n",
    "    :param labels: The corresponding labels.\n",
    "    :param subset_ratio: The fraction of the dataset to use.\n",
    "    :return: A tuple of (small_features, small_labels).\n",
    "    \"\"\"\n",
    "    small_features, _, small_labels, _ = train_test_split(\n",
    "        features, labels, test_size=subset_ratio, random_state=42\n",
    "    )\n",
    "    return small_features, small_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd5c8e7-eb37-4224-8926-0f4596918196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm test_features.pt train_features.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbe64bf-3065-4ed4-866f-22e33d33d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from disk.\n"
     ]
    }
   ],
   "source": [
    "# Main execution starts here\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "lfw_pairs_train, lfw_pairs_test = fetch_lfw_pairs(subset='train', color=True), fetch_lfw_pairs(subset='test', color=True)\n",
    "X_train_full, y_train_full, X_test_full, y_test_full = lfw_pairs_train.pairs, lfw_pairs_train.target, lfw_pairs_test.pairs, lfw_pairs_test.target\n",
    "small_train, small_train_y = create_small_dataset(X_train_full, y_train_full)\n",
    "small_test, small_test_y = create_small_dataset(X_test_full, y_test_full)\n",
    "\n",
    "# Optionally create a smaller dataset for quick prototyping\n",
    "use_small_dataset = False  # Set to False to use the full dataset\n",
    "\n",
    "if use_small_dataset:\n",
    "    X_train_full, y_train_full, X_test_full, y_test_full = small_train, small_train_y, small_test, small_test_y\n",
    "    \n",
    "# Check if precomputed features are already saved\n",
    "def load_features(filename):\n",
    "    if os.path.exists(filename):\n",
    "        return torch.load(filename)\n",
    "    return None\n",
    "\n",
    "train_features = load_features('train_features.pt')\n",
    "test_features = load_features('test_features.pt')\n",
    "\n",
    "if train_features is None or test_features is None:\n",
    "    print(\"Computing features...\")\n",
    "    train_features = compute_clip_features(X_train_full, model, preprocess, device)\n",
    "    test_features = compute_clip_features(X_test_full, model, preprocess, device)\n",
    "    torch.save(train_features, 'train_features.pt')\n",
    "    torch.save(test_features, 'test_features.pt')\n",
    "else:\n",
    "    print(\"Loaded features from disk.\")\n",
    "\n",
    "use_small_dataset = False\n",
    "\n",
    "if use_small_dataset:\n",
    "    small_train_features, small_train_labels = create_small_dataset(train_features, y_train_full)\n",
    "    small_test_features, small_test_labels = create_small_dataset(test_features, y_test_full)\n",
    "\n",
    "    train_dataset = LFWDatasetFeatures(small_train_features, small_train_labels)\n",
    "    test_dataset = LFWDatasetFeatures(small_test_features, small_test_labels)\n",
    "else:\n",
    "    train_dataset = LFWDatasetFeatures(train_features, y_train_full)\n",
    "    test_dataset = LFWDatasetFeatures(test_features, y_test_full)\n",
    "\n",
    "# Proceed with DataLoader, Model, Training, and Evaluation\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1851e6-afaf-419a-b369-aaecb8dfc794",
   "metadata": {},
   "source": [
    "We train a fully connected linear layer on top of CLIP on the LFW dataset from scikit-learn. \n",
    "The dataset consists of pairs of images of faces. Each image is 67 x 47 x 3\n",
    "The labels are True/False indicating whether the faces are of the same individual or not.\n",
    "Thus we train a simple binary classifcation fully connected linear layer on top of CLIP. CLIP weights are frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e57d461-3e6c-41ab-9b96-5b1bebd29126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      "        Train Loss: 0.7331,\n",
      "        Train Accuracy: 0.53, \n",
      "        Test Loss: 0.7253, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 10: \n",
      "        Train Loss: 0.7011,\n",
      "        Train Accuracy: 0.51, \n",
      "        Test Loss: 0.7168, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 20: \n",
      "        Train Loss: 0.6930,\n",
      "        Train Accuracy: 0.53, \n",
      "        Test Loss: 0.7394, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 30: \n",
      "        Train Loss: 0.6901,\n",
      "        Train Accuracy: 0.52, \n",
      "        Test Loss: 0.7070, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 40: \n",
      "        Train Loss: 0.6871,\n",
      "        Train Accuracy: 0.53, \n",
      "        Test Loss: 0.7039, \n",
      "        Test Accuracy: 0.48\n",
      "Epoch 50: \n",
      "        Train Loss: 0.6869,\n",
      "        Train Accuracy: 0.54, \n",
      "        Test Loss: 0.7020, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 60: \n",
      "        Train Loss: 0.6784,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.7377, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 70: \n",
      "        Train Loss: 0.6795,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.7047, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 80: \n",
      "        Train Loss: 0.6767,\n",
      "        Train Accuracy: 0.53, \n",
      "        Test Loss: 0.7325, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 90: \n",
      "        Train Loss: 0.6786,\n",
      "        Train Accuracy: 0.54, \n",
      "        Test Loss: 0.7194, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 100: \n",
      "        Train Loss: 0.6811,\n",
      "        Train Accuracy: 0.55, \n",
      "        Test Loss: 0.7576, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 110: \n",
      "        Train Loss: 0.6756,\n",
      "        Train Accuracy: 0.54, \n",
      "        Test Loss: 0.8025, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 120: \n",
      "        Train Loss: 0.6629,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.7272, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 130: \n",
      "        Train Loss: 0.6590,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.7241, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 140: \n",
      "        Train Loss: 0.6594,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.8361, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 150: \n",
      "        Train Loss: 0.6503,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.7657, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 160: \n",
      "        Train Loss: 0.6502,\n",
      "        Train Accuracy: 0.57, \n",
      "        Test Loss: 0.8056, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 170: \n",
      "        Train Loss: 0.6523,\n",
      "        Train Accuracy: 0.56, \n",
      "        Test Loss: 0.7860, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 180: \n",
      "        Train Loss: 0.6544,\n",
      "        Train Accuracy: 0.57, \n",
      "        Test Loss: 0.7732, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 190: \n",
      "        Train Loss: 0.6349,\n",
      "        Train Accuracy: 0.59, \n",
      "        Test Loss: 0.7788, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 200: \n",
      "        Train Loss: 0.6265,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 0.8910, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 210: \n",
      "        Train Loss: 0.6323,\n",
      "        Train Accuracy: 0.59, \n",
      "        Test Loss: 0.7874, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 220: \n",
      "        Train Loss: 0.6426,\n",
      "        Train Accuracy: 0.60, \n",
      "        Test Loss: 0.8132, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 230: \n",
      "        Train Loss: 0.6313,\n",
      "        Train Accuracy: 0.60, \n",
      "        Test Loss: 0.7565, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 240: \n",
      "        Train Loss: 0.6260,\n",
      "        Train Accuracy: 0.60, \n",
      "        Test Loss: 0.7898, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 250: \n",
      "        Train Loss: 0.6219,\n",
      "        Train Accuracy: 0.59, \n",
      "        Test Loss: 0.8037, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 260: \n",
      "        Train Loss: 0.6139,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 0.8429, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 270: \n",
      "        Train Loss: 0.6120,\n",
      "        Train Accuracy: 0.60, \n",
      "        Test Loss: 0.8330, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 280: \n",
      "        Train Loss: 0.6165,\n",
      "        Train Accuracy: 0.59, \n",
      "        Test Loss: 0.8455, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 290: \n",
      "        Train Loss: 0.6047,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 0.8940, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 300: \n",
      "        Train Loss: 0.6055,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 0.8152, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 310: \n",
      "        Train Loss: 0.6009,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 0.9731, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 320: \n",
      "        Train Loss: 0.6120,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 0.8366, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 330: \n",
      "        Train Loss: 0.5944,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 0.8733, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 340: \n",
      "        Train Loss: 0.6074,\n",
      "        Train Accuracy: 0.60, \n",
      "        Test Loss: 1.0623, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 350: \n",
      "        Train Loss: 0.5947,\n",
      "        Train Accuracy: 0.63, \n",
      "        Test Loss: 0.9953, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 360: \n",
      "        Train Loss: 0.5954,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 0.8443, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 370: \n",
      "        Train Loss: 0.6012,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 0.9378, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 380: \n",
      "        Train Loss: 0.5951,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 0.8779, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 390: \n",
      "        Train Loss: 0.5931,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 1.0821, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 400: \n",
      "        Train Loss: 0.5789,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.2603, \n",
      "        Test Accuracy: 0.48\n",
      "Epoch 410: \n",
      "        Train Loss: 0.5919,\n",
      "        Train Accuracy: 0.61, \n",
      "        Test Loss: 0.8699, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 420: \n",
      "        Train Loss: 0.6120,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 0.9930, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 430: \n",
      "        Train Loss: 0.5720,\n",
      "        Train Accuracy: 0.63, \n",
      "        Test Loss: 0.9238, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 440: \n",
      "        Train Loss: 0.5791,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 0.9159, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 450: \n",
      "        Train Loss: 0.5784,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 0.8941, \n",
      "        Test Accuracy: 0.48\n",
      "Epoch 460: \n",
      "        Train Loss: 0.5683,\n",
      "        Train Accuracy: 0.63, \n",
      "        Test Loss: 0.9887, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 470: \n",
      "        Train Loss: 0.5848,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 0.9573, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 480: \n",
      "        Train Loss: 0.5883,\n",
      "        Train Accuracy: 0.63, \n",
      "        Test Loss: 1.0651, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 490: \n",
      "        Train Loss: 0.5828,\n",
      "        Train Accuracy: 0.63, \n",
      "        Test Loss: 0.9401, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 500: \n",
      "        Train Loss: 0.5684,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.0372, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 510: \n",
      "        Train Loss: 0.5536,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.5182, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 520: \n",
      "        Train Loss: 0.5503,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 2.0676, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 530: \n",
      "        Train Loss: 0.5668,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.0305, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 540: \n",
      "        Train Loss: 0.5482,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 0.9430, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 550: \n",
      "        Train Loss: 0.5784,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.2477, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 560: \n",
      "        Train Loss: 0.5753,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.1088, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 570: \n",
      "        Train Loss: 0.5491,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 0.9864, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 580: \n",
      "        Train Loss: 0.5692,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.6113, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 590: \n",
      "        Train Loss: 0.5492,\n",
      "        Train Accuracy: 0.62, \n",
      "        Test Loss: 1.1313, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 600: \n",
      "        Train Loss: 0.5487,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.2904, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 610: \n",
      "        Train Loss: 0.5539,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.1077, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 620: \n",
      "        Train Loss: 0.5553,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 0.9655, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 630: \n",
      "        Train Loss: 0.5508,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.0607, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 640: \n",
      "        Train Loss: 0.5425,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.0051, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 650: \n",
      "        Train Loss: 0.5435,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.0013, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 660: \n",
      "        Train Loss: 0.5462,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.2320, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 670: \n",
      "        Train Loss: 0.5226,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.9851, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 680: \n",
      "        Train Loss: 0.5383,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 0.9853, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 690: \n",
      "        Train Loss: 0.5431,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.0022, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 700: \n",
      "        Train Loss: 0.5186,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.6919, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 710: \n",
      "        Train Loss: 0.5309,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.2128, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 720: \n",
      "        Train Loss: 0.5504,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.0925, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 730: \n",
      "        Train Loss: 0.5539,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.0373, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 740: \n",
      "        Train Loss: 0.5477,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.1045, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 750: \n",
      "        Train Loss: 0.5497,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.0048, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 760: \n",
      "        Train Loss: 0.5371,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 1.8145, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 770: \n",
      "        Train Loss: 0.5284,\n",
      "        Train Accuracy: 0.68, \n",
      "        Test Loss: 2.2204, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 780: \n",
      "        Train Loss: 0.5288,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.3333, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 790: \n",
      "        Train Loss: 0.5504,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.8947, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 800: \n",
      "        Train Loss: 0.5518,\n",
      "        Train Accuracy: 0.64, \n",
      "        Test Loss: 2.0217, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 810: \n",
      "        Train Loss: 0.5316,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.2733, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 820: \n",
      "        Train Loss: 0.5300,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.1734, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 830: \n",
      "        Train Loss: 0.5337,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.9667, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 840: \n",
      "        Train Loss: 0.5342,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.1813, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 850: \n",
      "        Train Loss: 0.5310,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.6182, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 860: \n",
      "        Train Loss: 0.5382,\n",
      "        Train Accuracy: 0.68, \n",
      "        Test Loss: 1.2194, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 870: \n",
      "        Train Loss: 0.5241,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 2.1636, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 880: \n",
      "        Train Loss: 0.5230,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 1.5040, \n",
      "        Test Accuracy: 0.49\n",
      "Epoch 890: \n",
      "        Train Loss: 0.5235,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.2619, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 900: \n",
      "        Train Loss: 0.5250,\n",
      "        Train Accuracy: 0.66, \n",
      "        Test Loss: 3.0912, \n",
      "        Test Accuracy: 0.52\n",
      "Epoch 910: \n",
      "        Train Loss: 0.5400,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.5626, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 920: \n",
      "        Train Loss: 0.5252,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.0994, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 930: \n",
      "        Train Loss: 0.5155,\n",
      "        Train Accuracy: 0.68, \n",
      "        Test Loss: 2.2349, \n",
      "        Test Accuracy: 0.48\n",
      "Epoch 940: \n",
      "        Train Loss: 0.5214,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.1263, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 950: \n",
      "        Train Loss: 0.5261,\n",
      "        Train Accuracy: 0.68, \n",
      "        Test Loss: 1.0178, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 960: \n",
      "        Train Loss: 0.5038,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 2.2720, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 970: \n",
      "        Train Loss: 0.5276,\n",
      "        Train Accuracy: 0.65, \n",
      "        Test Loss: 1.3943, \n",
      "        Test Accuracy: 0.50\n",
      "Epoch 980: \n",
      "        Train Loss: 0.5314,\n",
      "        Train Accuracy: 0.67, \n",
      "        Test Loss: 1.4026, \n",
      "        Test Accuracy: 0.51\n",
      "Epoch 990: \n",
      "        Train Loss: 0.5117,\n",
      "        Train Accuracy: 0.68, \n",
      "        Test Loss: 3.1294, \n",
      "        Test Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "\n",
    "custom_model_concat = CustomClassifierConcat().to(device).float()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(custom_model_concat.parameters(), lr=0.0005)\n",
    "\n",
    "# Main training loop\n",
    "num_epochs = 1000\n",
    "i = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(custom_model_concat, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_accuracy = evaluate(custom_model_concat, test_loader, criterion, device)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"\"\"Epoch {epoch}: \n",
    "        Train Loss: {train_loss:.4f},\n",
    "        Train Accuracy: {train_accuracy:.2f}, \n",
    "        Test Loss: {test_loss:.4f}, \n",
    "        Test Accuracy: {test_accuracy:.2f}\"\"\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d67a69-a543-418c-b452-b66041d062b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
